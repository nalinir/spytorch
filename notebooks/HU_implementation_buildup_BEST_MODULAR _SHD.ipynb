{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import get_shd_dataset\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the N-MNIST dataset\n",
    "import tonic\n",
    "\n",
    "train_dataset = tonic.datasets.NMNIST(save_to='./data', train=True, transform=None, target_transform=None)\n",
    "test_dataset = tonic.datasets.NMNIST(save_to='./data', train=False, transform=None, target_transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Model Settings\n",
    "\n",
    "We set them up here since some of the random manifold components are dependent on this so it has the right structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coarse network structure and the time steps are dicated by the SHD dataset. \n",
    "nb_inputs  = 700\n",
    "nb_hidden  = 200\n",
    "nb_outputs = 20\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps = 100\n",
    "max_time = 1.4\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.mps.benchmark = False\n",
    "torch.backends.mps.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "v1 = torch.empty((nb_hidden, nb_hidden), device=device, dtype=dtype, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import SHD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available at: /Users/naliniramanathan/data/hdspikes/shd_train.h5\n",
      "Available at: /Users/naliniramanathan/data/hdspikes/shd_test.h5\n"
     ]
    }
   ],
   "source": [
    "# Here we load the Dataset\n",
    "cache_dir = os.path.expanduser(\"~/data\")\n",
    "cache_subdir = \"hdspikes\"\n",
    "get_shd_dataset(cache_dir, cache_subdir)\n",
    "\n",
    "train_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_train.h5'), 'r')\n",
    "test_file = h5py.File(os.path.join(cache_dir, cache_subdir, 'shd_test.h5'), 'r')\n",
    "\n",
    "x_train = train_file['spikes']\n",
    "y_train = train_file['labels']\n",
    "x_test = test_file['spikes']\n",
    "y_test = test_file['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def non_sparse_data_generator_from_hdf5_spikes(X, y, batch_size, nb_steps, nb_units, max_time, device=device, shuffle=True):\n",
    "    \"\"\" This generator takes a spike dataset and generates spiking network input as dense tensors.\n",
    "\n",
    "    Args:\n",
    "        X: The data ( sample x event x 2 ) the last dim holds (time,neuron) tuples\n",
    "        y: The labels\n",
    "        batch_size: The number of samples per batch\n",
    "        nb_steps: The number of time steps\n",
    "        nb_units: The number of neurons\n",
    "        max_time: The maximum time value in the spike data\n",
    "        device: The torch device to use (e.g., 'cpu' or 'cuda')\n",
    "        shuffle: Whether to shuffle the data at the beginning of each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    labels_ = np.array(y, dtype=np.int64)\n",
    "    number_of_batches = len(labels_) // batch_size\n",
    "    sample_index = np.arange(len(labels_))\n",
    "\n",
    "    # compute discrete firing times\n",
    "    firing_times = X['times']\n",
    "    units_fired = X['units']\n",
    "\n",
    "    time_bins = np.linspace(0, max_time, num=nb_steps)\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "\n",
    "    total_batch_count = 0\n",
    "    counter = 0\n",
    "    while counter < number_of_batches:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "\n",
    "        X_batch = torch.zeros((batch_size, nb_steps, nb_units), dtype=torch.float32, device=device)\n",
    "        y_batch = torch.tensor(labels_[batch_index], device=device)\n",
    "\n",
    "        for bc, idx in enumerate(batch_index):\n",
    "            times = np.digitize(firing_times[idx], time_bins)\n",
    "            units = units_fired[idx]\n",
    "\n",
    "            # Filter out-of-bounds time indices\n",
    "            valid_indices = (times >= 0) & (times < nb_steps)\n",
    "            times = times[valid_indices]\n",
    "            units = units[valid_indices]\n",
    "\n",
    "            # Fill the dense tensor\n",
    "            X_batch[bc, times, units] = 1.0\n",
    "\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_subset_indices(data, limit, num_inputs = 10):\n",
    "    \"\"\"\n",
    "    Selects a representative subset of data point indices for PyTorch Subset,\n",
    "    using the number of unique labels as the number of representatives.\n",
    "\n",
    "    Args:\n",
    "        labels (np.ndarray or list): Array/list of labels for each data point.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of indices of the selected representative data points.\n",
    "    \"\"\"\n",
    "\n",
    "    num_representatives = len(data)  # Use number of unique labels\n",
    "\n",
    "    representatives_per_class = num_representatives//num_inputs\n",
    "    sample_per_class = limit // num_inputs\n",
    "    selected_indices = []\n",
    "    for i in range(num_inputs):\n",
    "        range_v = np.arange(i*representatives_per_class, (i+1)*representatives_per_class)\n",
    "        selected_indices.extend(np.random.choice(range_v, sample_per_class, replace=False))\n",
    "        # selected_indices.append(np.random.choice(indices, 1, replace=False).item()) #ensure only one item is selected.\n",
    "\n",
    "    return torch.tensor(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_spike_events' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[222], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m train_subset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubset(train_dataset, train_subset_indices)\n\u001b[1;32m     10\u001b[0m test_subset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mSubset(test_dataset, test_subset_indices)\n\u001b[0;32m---> 12\u001b[0m train_x_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mpreprocess_spike_events\u001b[49m(sample, nb_steps, nb_units\u001b[38;5;241m=\u001b[39mnb_inputs) \u001b[38;5;28;01mfor\u001b[39;00m sample, _ \u001b[38;5;129;01min\u001b[39;00m train_subset])\n\u001b[1;32m     13\u001b[0m train_y_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([label \u001b[38;5;28;01mfor\u001b[39;00m _, label \u001b[38;5;129;01min\u001b[39;00m train_subset], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)  \u001b[38;5;66;03m# Shape: (num_samples,)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TensorDataset(train_x_data, train_y_tensor)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_spike_events' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "\n",
    "train_limit = 200\n",
    "test_limit = 200\n",
    "# train_dataset = test_dataset\n",
    "train_subset_indices = get_representative_subset_indices(train_dataset, train_limit)\n",
    "test_subset_indices = get_representative_subset_indices(test_dataset, test_limit)\n",
    "\n",
    "train_subset = torch.utils.data.Subset(train_dataset, train_subset_indices)\n",
    "test_subset = torch.utils.data.Subset(test_dataset, test_subset_indices)\n",
    "\n",
    "train_x_data = torch.stack([preprocess_spike_events(sample, nb_steps, nb_units=nb_inputs) for sample, _ in train_subset])\n",
    "train_y_tensor = torch.tensor([label for _, label in train_subset], dtype=torch.int64)  # Shape: (num_samples,)\n",
    "\n",
    "train_data = TensorDataset(train_x_data, train_y_tensor)\n",
    "\n",
    "test_x_data = torch.stack([preprocess_spike_events(sample, nb_steps, nb_units=nb_inputs) for sample, _ in test_subset])\n",
    "test_y_tensor = torch.tensor([label for _, label in test_subset], dtype=torch.int64)  # Shape: (num_samples,)\n",
    "\n",
    "test_data = TensorDataset(test_x_data, test_y_tensor)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    # collate_fn=custom_collate_fn,  # Use the custom collate function\n",
    "    # num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    # collate_fn=custom_collate_fn,  # Use the custom collate function\n",
    "    # num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# nb_steps = train_dataset[0][0].shape[0] # Get the number of time steps\n",
    "nb_inputs = 34 * 34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Baseline SNN Hybrid Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation - No Recurrent Weights\n",
    "\n",
    "The input is a set of spikes. At each timestep, certain SNN neurons fire in response to those inputs. The ANNs act as recurrent units within the network. We'll exclude the recurrent weights to simplify things to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNN Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_fn(x):\n",
    "    out = torch.zeros_like(x)\n",
    "    out[x > 0] = 1.0\n",
    "    return out\n",
    "\n",
    "def SNN(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(timesteps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(timesteps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(timesteps=nb_steps, model = SNN):\n",
    "    \"\"\" Dirty little helper function to compute classification accuracy. \"\"\"\n",
    "    output,_ = model(x_data)\n",
    "    m,_= torch.max(output,1) # max over time\n",
    "    _,am=torch.max(m,1) # argmax over output units\n",
    "    am = am.detach().cpu().numpy() # convert to numpy\n",
    "    # Compute accuracy\n",
    "    acc = np.mean((y_data.detach().cpu().numpy()==am))\n",
    "    print(\"Accuracy %.3f\"%acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SNN Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SNN Recurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNN_recurrent(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    out = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    h1_from_input = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(timesteps):\n",
    "        h1 = h1_from_input[:,t] + torch.einsum(\"ab,bc->ac\", (out, v1))\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(timesteps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN Only\n",
    "\n",
    "Let's model an RNN with a similar structure to our SNN. It will take in our temporal data (spikes), and then transform it accordingly in each layer using the weights.\n",
    "\n",
    "Since we take spikes, weight them, and then output them using traditional tanh, we don't really need to worry about conversion.\n",
    "\n",
    "We'd usually have recurrent weights for the RNN, but since we excluded them for the SNN we'll do the same here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_non_recurrent_with_LIF_output(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    # Weights for the hidden layer for RNN is just w1 -- multiplying by inputs just gives us the output at each timestep\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # We could also add a bias term but let's exclude for now to make the merging more simple\n",
    "\n",
    "    interim_rec = []\n",
    "\n",
    "    # The difference for a pure ANN is that the hidden and the output layer usually happen at the same time\n",
    "    # It's really fine that they're different here though if we just compute them sequentially\n",
    "\n",
    "    for t in range(timesteps):\n",
    "\n",
    "        layer_weights = h1[:,t]\n",
    "\n",
    "        # Use a tanh function similar to what's done in other models\n",
    "        out = torch.tanh(layer_weights)\n",
    "        interim_rec.append(out)\n",
    "\n",
    "    interim_rec = torch.stack(interim_rec,dim=1)\n",
    "    # We will use the same LIF model as before, and just use the raw output as an input to start since it has a window of 1\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (interim_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "\n",
    "    # Convert the h2 readout layer to a rate that can be transmitted to the output layer\n",
    "    \n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = interim_rec\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_with_LIF_output(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    # Weights for the hidden layer for RNN is just w1 -- multiplying by inputs just gives us the output at each timestep\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # We could also add a bias term but let's exclude for now to make the merging more simple\n",
    "\n",
    "    interim_rec = []\n",
    "    \n",
    "    # The difference for a pure ANN is that the hidden and the output layer usually happen at the same time\n",
    "    # It's really fine that they're different here though if we just compute them sequentially\n",
    "    out = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    for t in range(timesteps):\n",
    "\n",
    "        layer_weights = h1[:,t] + torch.einsum(\"ab,bc->ac\", (out, v1))\n",
    "\n",
    "        # Use a tanh function similar to what's done in other models\n",
    "        out = torch.tanh(layer_weights)\n",
    "        interim_rec.append(out)\n",
    "\n",
    "    interim_rec = torch.stack(interim_rec,dim=1)\n",
    "    # We will use the same LIF model as before, and just use the raw output as an input to start since it has a window of 1\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (interim_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "\n",
    "    # Convert the h2 readout layer to a rate that can be transmitted to the output layer\n",
    "    \n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = interim_rec\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANN and SNN - Network to Network\n",
    "\n",
    "For this implementation, we just have 1 timestep, so we don't need to worry about converting ANN to SNN or any of the intermediary weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        1., 1.], device='mps:0')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "snn_mask = torch.randint(0, 2, (nb_hidden,), dtype=torch.float32, device=device)  # Randomly assign spiking or analog neurons\n",
    "snn_mask # 1 is spiking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options for SNN to ANN conversion include:\n",
    "1. Time of first spike (this makes less sense with a window of size one)\n",
    "2. Rate (this also makes less sense with a window of size one)\n",
    "3. ISI (it's a difference between spikes so I think this also makes less sense)\n",
    "4. Just take it and weight it (learnable) --> trying this first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_ANN_non_recurrent(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    # Weight matrix for training, I think this can be used for both SNN and ANN but the training may have to be different\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # Let's just do 2 matrices to keep it clean for now\n",
    "    h1_ann = h1.clone() * (1.0-snn_mask)  # ANN neurons\n",
    "    h1_snn = h1.clone() * snn_mask  # SNN neurons\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    ann_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(timesteps):\n",
    "\n",
    "        # SNN neurons\n",
    "\n",
    "        # Apply the mask to the synaptic input to ensure SNN neurons are only updated with spiking rules\n",
    "        mem = mem*snn_mask\n",
    "        syn = syn*snn_mask\n",
    "\n",
    "        mthr = mem-1.0\n",
    "        out_snn = spike_fn(mthr)\n",
    "        rst = out_snn.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1_snn[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out_snn)\n",
    "\n",
    "        # ANN neurons - don't interact with the synaptic input at all to start\n",
    "        out_ann = torch.tanh(h1_ann[:,t])\n",
    "        ann_rec.append(out_ann)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "    ann_rec = torch.stack(ann_rec,dim=1)\n",
    "\n",
    "    h2_snn = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    h2_ann= torch.einsum(\"abc,cd->abd\", (ann_rec, w2))\n",
    "\n",
    "    # We can add the two together to get the final output since the two do not interact at all\n",
    "    h2 = h2_snn + h2_ann\n",
    "\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(timesteps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec, ann_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_RNN(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    # Weight matrix for training, I think this can be used for both SNN and ANN but the training may have to be different\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # Let's just do 2 matrices to keep it clean for now\n",
    "    h1_ann = h1.clone() * (1.0-snn_mask)  # ANN neurons\n",
    "    h1_snn = h1.clone() * snn_mask  # SNN neurons\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    ann_rec = []\n",
    "\n",
    "    out_ann = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    \n",
    "    # Compute hidden layer activity\n",
    "    for t in range(timesteps):\n",
    "\n",
    "        # SNN neurons\n",
    "\n",
    "        # Apply the mask to the synaptic input to ensure SNN neurons are only updated with spiking rules\n",
    "        mem = mem*snn_mask\n",
    "        syn = syn*snn_mask\n",
    "\n",
    "        mthr = mem-1.0\n",
    "        out_snn = spike_fn(mthr)\n",
    "        rst = out_snn.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1_snn[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out_snn)\n",
    "\n",
    "        # ANN neurons - don't interact with the synaptic input at all to start\n",
    "        out_ann = torch.tanh(h1_ann[:,t]) + torch.einsum(\"ab,bc->ac\", (out_ann, v1))\n",
    "        ann_rec.append(out_ann)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "    ann_rec = torch.stack(ann_rec,dim=1)\n",
    "\n",
    "    h2_snn = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    h2_ann= torch.einsum(\"abc,cd->abd\", (ann_rec, w2))\n",
    "\n",
    "    # We can add the two together to get the final output since the two do not interact at all\n",
    "    h2 = h2_snn + h2_ann\n",
    "\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(timesteps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec, ann_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recurrent SNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_RNN_SNN_rec(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    # Weight matrix for training, I think this can be used for both SNN and ANN but the training may have to be different\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # Let's just do 2 matrices to keep it clean for now\n",
    "    h1_ann = h1.clone() * (1.0-snn_mask)  # ANN neurons\n",
    "    h1_snn_input = h1.clone() * snn_mask  # SNN neurons\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    ann_rec = []\n",
    "\n",
    "    out_ann = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    out_snn = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(timesteps):\n",
    "        h1_snn = h1_snn_input[:,t] + torch.einsum(\"ab,bc->ac\", (out_snn, v1))\n",
    "        # SNN neurons\n",
    "\n",
    "        # Apply the mask to the synaptic input to ensure SNN neurons are only updated with spiking rules\n",
    "        mem = mem*snn_mask\n",
    "        syn = syn*snn_mask\n",
    "\n",
    "        mthr = mem-1.0\n",
    "        out_snn = spike_fn(mthr)\n",
    "        rst = out_snn.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1_snn\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out_snn)\n",
    "\n",
    "        # ANN neurons - don't interact with the synaptic input at all to start\n",
    "        out_ann = torch.tanh(h1_ann[:,t]) + torch.einsum(\"ab,bc->ac\", (out_ann, v1))\n",
    "        ann_rec.append(out_ann)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "    ann_rec = torch.stack(ann_rec,dim=1)\n",
    "\n",
    "    h2_snn = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    h2_ann= torch.einsum(\"abc,cd->abd\", (ann_rec, w2))\n",
    "\n",
    "    # We can add the two together to get the final output since the two do not interact at all\n",
    "    h2 = h2_snn + h2_ann\n",
    "\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(timesteps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec, ann_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN and SNN - Layer to Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hybrid_RNN_SNN_V1_same_layer(inputs, timesteps=nb_steps):\n",
    "    inputs = inputs.to(device)\n",
    "    # Weight matrix for training, I think this can be used for both SNN and ANN but the training may have to be different\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    # Let's just do 2 matrices to keep it clean for now\n",
    "    h1_ann = h1.clone() * (1.0-snn_mask)  # ANN neurons\n",
    "    h1_snn_input = h1.clone() * snn_mask  # SNN neurons\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "    ann_rec = []\n",
    "    # (O_A + O_S) * W_2 = (O_A * W_2 + O_S * W_2) by distributive property, no theoretical change there apart from H1\n",
    "    # Prove/think about this after more after test it\n",
    "    out_ann = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    out_snn = torch.zeros((batch_size, nb_hidden), device=device, dtype=dtype)\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(timesteps):\n",
    "        out = out_ann + out_snn\n",
    "        h1_snn = h1_snn_input[:,t] + torch.einsum(\"ab,bc->ac\", (out, v1))\n",
    "        # SNN neurons\n",
    "\n",
    "        # Apply the mask to the synaptic input to ensure SNN neurons are only updated with spiking rules\n",
    "        mem = mem*snn_mask\n",
    "        syn = syn*snn_mask\n",
    "\n",
    "        mthr = mem-1.0\n",
    "        out_snn = spike_fn(mthr)\n",
    "        rst = out_snn.detach() # We do not want to backprop through the reset\n",
    "\n",
    "        new_syn = alpha*syn +h1_snn\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out_snn)\n",
    "\n",
    "        # ANN neurons - don't interact with the synaptic input at all to start\n",
    "        out_ann = torch.tanh(h1_ann[:,t]) + torch.einsum(\"ab,bc->ac\", (out, v1))\n",
    "        ann_rec.append(out_ann)\n",
    "        \n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "    ann_rec = torch.stack(ann_rec,dim=1)\n",
    "\n",
    "    h2_snn = torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    h2_ann = torch.einsum(\"abc,cd->abd\", (ann_rec, w2))\n",
    "\n",
    "    # We can add the two together to get the final output since the two do not interact at all\n",
    "    h2 = h2_snn + h2_ann\n",
    "\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(timesteps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec, ann_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Training (Surrogate Gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_classification_accuracy(data_loader, model):\n",
    "    \"\"\" \n",
    "    Computes classification accuracy and confusion matrix on supplied data in batches.\n",
    "    \n",
    "    Returns:\n",
    "        accuracy: Overall classification accuracy.\n",
    "        conf_matrix: Confusion matrix of shape (num_classes, num_classes).\n",
    "    \"\"\"\n",
    "    accs = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    spike_count = 0\n",
    "    for x_local, y_local in non_sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time, shuffle=False):\n",
    "        # Move data to the appropriate device\n",
    "        x_local, y_local = x_local.to(device), y_local.to(device)\n",
    "\n",
    "        # Run the SNN model\n",
    "        output, other_recs = model(x_local)\n",
    "        spks = other_recs[1].clone() # spiking activity\n",
    "                # just include spikes greater than 1 and do a count of them\n",
    "        spks[spks<1.0] = 0.0\n",
    "        spks[spks>1.0] = 1.0\n",
    "        spike_count += torch.sum(spks).detach().cpu().numpy()\n",
    "        # Compute predictions\n",
    "        m, _ = torch.max(output, 1)  # Max over time\n",
    "        _, preds = torch.max(m, 1)   # Argmax over output units\n",
    "\n",
    "        # Compute accuracy for the current batch\n",
    "        correct = (y_local == preds).float()  # Shape: [batch_size]\n",
    "        tmp = correct.mean().item()  # Accuracy for the current batch\n",
    "        accs.append(tmp)\n",
    "\n",
    "        # Store predictions and labels for the confusion matrix\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_local.cpu().numpy())\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    accuracy = np.mean(accs)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, conf_matrix, spike_count\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, class_names, title):\n",
    "    \"\"\" Plots the confusion matrix. \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"{title} Confusion Matrix - Random Manifolds\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_print_results(model, x_data=x_train, y_data=y_train, epochs=100, regularization=False, l1=1e-5, l2=1e-5):\n",
    "    global w1, w2, v1\n",
    "    # The following lines will reinitialize the weights\n",
    "    torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "    torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "    torch.nn.init.normal_(v1, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "    print(\"init done\")\n",
    "\n",
    "    params = [w1,w2, v1]\n",
    "    optimizer = torch.optim.Adam(params, lr=2e-3, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    spike_count = 0\n",
    "    loss_hist = []\n",
    "    for e in range(epochs):\n",
    "        local_loss = []\n",
    "        # with tqdm(train_loader, desc=f\"Epoch {e+1}/{nb_epochs}\", unit=\"batch\") as t:\n",
    "        for x_local, y_local in non_sparse_data_generator_from_hdf5_spikes(x_data, y_data, batch_size, nb_steps, nb_inputs, max_time, shuffle=False):\n",
    "            x_local = x_local.to(device)\n",
    "            y_local = y_local.to(device)\n",
    "            output, other_recs = model(x_local)  # Assuming run_snn() is integrated into model\n",
    "            m,_=torch.max(output,1)\n",
    "            log_p_y = log_softmax_fn(m)\n",
    "            if \"SNN\" or \"Hybrid\" in model.__name__:\n",
    "                spks = other_recs[1].clone() # spiking activity\n",
    "                # just include spikes greater than 1 and do a count of them\n",
    "                spks[spks<1.0] = 0.0\n",
    "                spks[spks>1.0] = 1.0\n",
    "                spike_count += torch.sum(spks).detach().cpu().numpy()\n",
    "            loss_val = loss_fn(log_p_y, y_local)\n",
    "            if regularization:\n",
    "                spks = other_recs[1]\n",
    "                reg_loss = l1*torch.sum(spks) # L1 loss on total number of spikes\n",
    "                reg_loss += l2*torch.mean(torch.sum(torch.sum(spks,dim=0),dim=0)**2) # L2 loss on spikes per neuron\n",
    "                loss_val += reg_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            local_loss.append(loss_val.item())\n",
    "        loss_hist.append(np.mean(local_loss))\n",
    "\n",
    "    plt.plot(loss_hist)\n",
    "    plt.title(f\"{model.__name__} Loss - Regularization: {regularization}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    sns.despine()\n",
    "    # output,other_recs_h = model(x_data)\n",
    "    # fig=plt.figure(dpi=100)\n",
    "    # plot_voltage_traces(other_recs_h[0],other_recs_h[1],dim=(2,5))\n",
    "    fig=plt.figure(dpi=100)\n",
    "    # if 'run_hybrid' in model.__name__:\n",
    "    #     plot_voltage_traces(other_recs_h[2],dim=(2,5))\n",
    "    #     fig=plt.figure(dpi=100)\n",
    "    plot_voltage_traces(output,dim=(2,5))\n",
    "    train_accuracy, train_conf_matrix, _ = compute_classification_accuracy(x_data, y_data, model=model)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    class_names = [f\"Class {i}\" for i in range(nb_outputs)]\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plot_confusion_matrix(train_conf_matrix, class_names, f\"{model.__name__} Train Results - Regularization: {regularization}\")\n",
    "    test_accuracy, test_conf_matrix, _ = compute_classification_accuracy(x_test, y_test, model=model)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    class_names = [f\"Class {i}\" for i in range(nb_outputs)]\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plot_confusion_matrix(test_conf_matrix, class_names, f\"{model.__name__} Train Results - Regularization: {regularization}\")\n",
    "    return spike_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[213], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_and_print_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSNN_recurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregularization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[212], line 20\u001b[0m, in \u001b[0;36mtrain_and_print_results\u001b[0;34m(model, x_data, y_data, epochs, regularization, l1, l2)\u001b[0m\n\u001b[1;32m     18\u001b[0m local_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# with tqdm(train_loader, desc=f\"Epoch {e+1}/{nb_epochs}\", unit=\"batch\") as t:\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_local\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_local\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnon_sparse_data_generator_from_hdf5_spikes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_local\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_local\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_local\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_local\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[197], line 49\u001b[0m, in \u001b[0;36mnon_sparse_data_generator_from_hdf5_spikes\u001b[0;34m(X, y, batch_size, nb_steps, nb_units, max_time, device, shuffle)\u001b[0m\n\u001b[1;32m     46\u001b[0m     units \u001b[38;5;241m=\u001b[39m units[valid_indices]\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Fill the dense tensor\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     X_batch[bc, times, units] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m X_batch, y_batch\n\u001b[1;32m     53\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_and_print_results(SNN_recurrent, epochs=40, regularization=True, l1=1e-6, l2=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "train_and_print_results(SNN, epochs=40, regularization=True, l1=1e-6, l2=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: SNN\n",
      "Regularization disabled\n",
      "init done\n"
     ]
    }
   ],
   "source": [
    "models = [SNN, SNN_recurrent, ANN_non_recurrent_with_LIF_output, RNN_with_LIF_output, Hybrid_ANN_non_recurrent, Hybrid_RNN, Hybrid_RNN_SNN_rec]\n",
    "# Create a table with all the model accuracies\n",
    "model_accuracies = {}\n",
    "for model in models:\n",
    "    print(f\"Training model: {model.__name__}\")\n",
    "    print(\"Regularization disabled\")\n",
    "    spike_count = train_and_print_results(model, epochs=40)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    acc, matrix, spike_count_t = compute_classification_accuracy(x_test, y_test, model=model)\n",
    "    model_accuracies[model.__name__+\"_No_Regularization\"] = (acc, spike_count, spike_count_t)\n",
    "    if \"SNN\" in model.__name__:\n",
    "        print(f\"Training model: {model.__name__}\")\n",
    "        print(\"Regularization enabled\")\n",
    "        train_and_print_results(model, epochs=40, regularization=True)\n",
    "        acc, matrix, spike_count_t = compute_classification_accuracy(x_test, y_test, model=model)\n",
    "        model_accuracies[model.__name__+\"_Regularization\"] = (acc, spike_count, spike_count_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skip to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SNN': 1.0,\n",
       " 'SNN_recurrent': 0.98046875,\n",
       " 'ANN_non_recurrent_with_LIF_output': 0.98046875,\n",
       " 'RNN_with_LIF_output': 0.96875,\n",
       " 'Hybrid_ANN_non_recurrent': 1.0,\n",
       " 'Hybrid_RNN': 0.99609375,\n",
       " 'Hybrid_RNN_SNN_rec': 0.515625}"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model, (acc, spike1, spike2) in model_accuracies.items():\n",
    "    print(f\"{model}: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, (acc, spike1, spike2) in model_accuracies.items():\n",
    "    print(f\"{model}: {spike1:,} Training, {spike2:,} Testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
