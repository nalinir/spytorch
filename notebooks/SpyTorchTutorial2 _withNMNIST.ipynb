{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKJ0BjXaUwcT"
   },
   "source": [
    "# Tutorial 2: Training a spiking neural network on a simple vision dataset\n",
    "\n",
    "Friedemann Zenke (https://fzenke.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JblnYVhuUwcW"
   },
   "source": [
    "> For more details on surrogate gradient learning, please see:\n",
    "> Neftci, E.O., Mostafa, H., and Zenke, F. (2019). Surrogate Gradient Learning in Spiking Neural Networks.\n",
    "> https://arxiv.org/abs/1901.09948"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSbGiuOkUwcW"
   },
   "source": [
    "In Tutorial 1, we have seen how to train a simple multi-layer spiking neural network on a small synthetic dataset. In this tutorial, we will apply what we have learned so far to a slightly larger dataset.\n",
    "Concretely, we will use the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2544,
     "status": "ok",
     "timestamp": 1741063343202,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "h7VNlYaJWxMa",
    "outputId": "dbd03e68-42ff-419d-cade-09226cf402ae"
   },
   "outputs": [],
   "source": [
    "# !pip install tonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2MjziHmvUwcW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1741063343278,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "4-wgCxnXUwcX",
    "outputId": "39bb8fc9-5b2a-401b-fbac-7ea890febc0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-9vv4MEfUwcY"
   },
   "outputs": [],
   "source": [
    "# The coarse network structure is dicated by the Fashion MNIST dataset.\n",
    "nb_inputs  = 34*34 # https://greg-cohen.com/project/datasets/\n",
    "nb_hidden  = 100\n",
    "nb_outputs = 10\n",
    "\n",
    "time_step = 1e-3\n",
    "nb_steps  = 100\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1741063343434,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "2IjPt1OVUwcY",
    "outputId": "63fc1995-47f8-4988-930e-a82a073c974a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TsIXd7vdUwcY"
   },
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "\n",
    "# Check whether a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9tzC5HVWvZc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eg-xUwQTUwcY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 to ./data/NMNIST/train.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 89085952/1011893601 [10:04<1:44:23, 147331.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Load in the N-MNIST dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtonic\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtonic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m tonic\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mNMNIST(save_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tonic/datasets/nmnist.py:96\u001b[0m, in \u001b[0;36mNMNIST.__init__\u001b[0;34m(self, save_to, train, first_saccade_only, stabilize, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_folder\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation_on_system, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder_name)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path, dirs, files \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(file_path):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tonic/dataset.py:34\u001b[0m, in \u001b[0;36mDataset.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Downloads from a given url, places into target folder and verifies the file hash.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation_on_system\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_md5\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tonic/download_utils.py:320\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    319\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 320\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(archive, extract_root))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tonic/download_utils.py:128\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[0;32m--> 128\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mIOError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tonic/download_utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m     27\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})\n\u001b[1;32m     28\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/site-packages/tonic/download_utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m     27\u001b[0m     urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})\n\u001b[1;32m     28\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     32\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/socket.py:719\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot read from timed out object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/ssl.py:1304\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1303\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/snn_hybrid/lib/python3.13/ssl.py:1138\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Load in the N-MNIST dataset\n",
    "import tonic\n",
    "\n",
    "train_dataset = tonic.datasets.NMNIST(save_to='./data', train=True, transform=None, target_transform=None)\n",
    "test_dataset = tonic.datasets.NMNIST(save_to='./data', train=False, transform=None, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741063343896,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "FUZ1T8_rUwcY",
    "outputId": "43d33f49-f156-4c2c-b7de-5722fc1dfee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([(10, 30,    937, 1), (33, 20,   1030, 1), (12, 27,   1052, 1), ...,\n",
      "       ( 7, 15, 302706, 1), (26, 11, 303852, 1), (11, 17, 305341, 1)],\n",
      "      dtype=[('x', '<i8'), ('y', '<i8'), ('t', '<i8'), ('p', '<i8')]), 0)\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL5LBL9XUwcZ"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def preprocess_spike_events(spike_events, nb_steps=nb_steps, nb_units=nb_inputs):\n",
    "    \"\"\"\n",
    "    Convert spike events into a binned spike train.\n",
    "\n",
    "    Args:\n",
    "        spike_events: Structured NumPy array of spike events (x, y, t, p).\n",
    "        nb_steps: Number of time steps to bin the spikes into.\n",
    "        nb_units: Number of neurons (x * y resolution).\n",
    "\n",
    "    Returns:\n",
    "        A binned spike train of shape (nb_steps, nb_units).\n",
    "    \"\"\"\n",
    "    spike_train = np.zeros((nb_steps, nb_units), dtype=np.float32)\n",
    "    for x, y, t, p in spike_events:\n",
    "        if p == 1:  # Only process the event if p indicates a spike\n",
    "            time_bin = min(int(t / 1000), nb_steps - 1)  # Bin time into steps\n",
    "            neuron_id = x + y * int(np.sqrt(nb_inputs))  # Flatten 2D coordinates into 1D neuron ID\n",
    "            spike_train[time_bin, neuron_id] += 1\n",
    "\n",
    "    return torch.tensor(spike_train, dtype=torch.float32)\n",
    "\n",
    "def custom_collate_fn(batch, num_classes=10):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle structured data and one-hot encode the labels.\n",
    "\n",
    "    Args:\n",
    "        batch: A list of samples (spike_events, label).\n",
    "        num_classes: Number of classes for one-hot encoding.\n",
    "\n",
    "    Returns:\n",
    "        A tuple (spike_tensors, one_hot_labels).\n",
    "    \"\"\"\n",
    "    spike_tensors = []\n",
    "    labels = []\n",
    "\n",
    "    for spike_events, label in batch:\n",
    "        # Preprocess spike events\n",
    "        spike_tensor = preprocess_spike_events(spike_events)\n",
    "        spike_tensors.append(spike_tensor)\n",
    "\n",
    "        # One-hot encode the label\n",
    "        one_hot_label = F.one_hot(torch.tensor(label, dtype=torch.int64), num_classes=num_classes)\n",
    "        labels.append(one_hot_label)\n",
    "\n",
    "    # Stack spike tensors and labels into batches\n",
    "    spike_tensors = torch.stack(spike_tensors)\n",
    "    labels = torch.stack(labels)  # Convert list of one-hot labels into a batch\n",
    "    return spike_tensors, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvaoctQLUwcZ"
   },
   "outputs": [],
   "source": [
    "# REDO - get the representative split for the subset retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtZamOqVUwcZ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "train_limit\n",
    "test_limit\n",
    "\n",
    "train_subset = torch.utils.data.Subset(train_dataset, range(1000))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate_fn,  # Use the custom collate function\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# nb_steps = train_dataset[0][0].shape[0] # Get the number of time steps\n",
    "nb_inputs = 34 * 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1741063344010,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "G1k9Y9TWUwcZ",
    "outputId": "2fa10f4a-d531-4e5b-fde9-d2e8f3c392e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5028\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXGM0v_PUwcZ"
   },
   "source": [
    "Since we are working with spiking neural networks, we ideally want to use a temporal code to make use of spike timing. To that end, we will use a spike latency code to feed spikes to our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBu9tx1lUwcZ"
   },
   "source": [
    "### Setup of the spiking network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdomR_nnUwcZ"
   },
   "outputs": [],
   "source": [
    "tau_mem = 10e-3\n",
    "tau_syn = 5e-3\n",
    "\n",
    "alpha   = float(np.exp(-time_step/tau_syn))\n",
    "beta    = float(np.exp(-time_step/tau_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1741063344040,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "7xx1F6fPUwcZ",
    "outputId": "ebfb54fb-ddcc-435f-8cbd-4171470e1f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init done\n"
     ]
    }
   ],
   "source": [
    "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
    "\n",
    "w1 = torch.empty((nb_inputs, nb_hidden),  device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_outputs), device=device, dtype=dtype, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0.0, std=weight_scale/np.sqrt(nb_hidden))\n",
    "\n",
    "print(\"init done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AjbWEQSUwca"
   },
   "outputs": [],
   "source": [
    "def plot_voltage_traces(mem, spk=None, dim=(3,5), spike_height=5):\n",
    "    gs=GridSpec(*dim)\n",
    "    if spk is not None:\n",
    "        dat = 1.0*mem\n",
    "        dat[spk>0.0] = spike_height\n",
    "        dat = dat.detach().cpu().numpy()\n",
    "    else:\n",
    "        dat = mem.detach().cpu().numpy()\n",
    "    for i in range(np.prod(dim)):\n",
    "        if i==0: a0=ax=plt.subplot(gs[i])\n",
    "        else: ax=plt.subplot(gs[i],sharey=a0)\n",
    "        ax.plot(dat[i])\n",
    "        ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQqtCHbRUwca"
   },
   "source": [
    "We can now run this code and plot the output layer \"membrane potentials\" below. As desired, these potentials do not have spikes riding on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5C7SzdTUwca"
   },
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bkf1vVzUwca"
   },
   "outputs": [],
   "source": [
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements\n",
    "    the surrogate gradient. By subclassing torch.autograd.Function,\n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid\n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "\n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which\n",
    "        we need to later backpropagate our error signals. To achieve this we use the\n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the\n",
    "        surrogate gradient of the loss with respect to the input.\n",
    "        Here we use the normalized negative part of a fast sigmoid\n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "\n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "spike_fn  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0txOrAMUwca"
   },
   "outputs": [],
   "source": [
    "def run_snn(inputs):\n",
    "    h1 = torch.einsum(\"abc,cd->abd\", (inputs, w1))\n",
    "    syn = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "    mem = torch.zeros((batch_size,nb_hidden), device=device, dtype=dtype)\n",
    "\n",
    "    mem_rec = []\n",
    "    spk_rec = []\n",
    "\n",
    "    # Compute hidden layer activity\n",
    "    for t in range(nb_steps):\n",
    "        mthr = mem-1.0\n",
    "        out = spike_fn(mthr)\n",
    "        rst = out.detach() # We do not want to backprop through the reset\n",
    "        # print(f\"h1[:, t] shape: {h1[:, t].shape}\")\n",
    "        # print(f\"syn shape: {syn.shape}\")\n",
    "\n",
    "        new_syn = alpha*syn +h1[:,t]\n",
    "        new_mem = (beta*mem +syn)*(1.0-rst)\n",
    "\n",
    "        mem_rec.append(mem)\n",
    "        spk_rec.append(out)\n",
    "\n",
    "        mem = new_mem\n",
    "        syn = new_syn\n",
    "\n",
    "    mem_rec = torch.stack(mem_rec,dim=1)\n",
    "    spk_rec = torch.stack(spk_rec,dim=1)\n",
    "\n",
    "    # Readout layer\n",
    "    h2= torch.einsum(\"abc,cd->abd\", (spk_rec, w2))\n",
    "    flt = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out = torch.zeros((batch_size,nb_outputs), device=device, dtype=dtype)\n",
    "    out_rec = [out]\n",
    "    for t in range(nb_steps):\n",
    "        new_flt = alpha*flt +h2[:,t]\n",
    "        new_out = beta*out +flt\n",
    "\n",
    "        flt = new_flt\n",
    "        out = new_out\n",
    "\n",
    "        out_rec.append(out)\n",
    "\n",
    "    out_rec = torch.stack(out_rec,dim=1)\n",
    "    other_recs = [mem_rec, spk_rec]\n",
    "    return out_rec, other_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6_fzI_OUwca"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(train_loader, lr=2e-3, nb_epochs=10):\n",
    "    params = [w1,w2]\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, betas=(0.9,0.999))\n",
    "\n",
    "    log_softmax_fn = nn.LogSoftmax(dim=1)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    loss_hist = []\n",
    "\n",
    "    # scaler = torch.amp.GradScaler(device=device) if device.type == 'cuda' else None\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        local_loss = []\n",
    "        with tqdm(train_loader, desc=f\"Epoch {e+1}/{nb_epochs}\", unit=\"batch\") as t:\n",
    "            for x_local, y_local in t:\n",
    "                x_local = x_local.to(device)\n",
    "                y_local = y_local.to(device)\n",
    "\n",
    "                # print(f\"Input dimensions: x_local.shape = {x_local.shape}, y_local.shape = {y_local.shape}\")\n",
    "\n",
    "                # # with torch.amp.autocast(device_type=device.type, enabled=(scaler is not None)):  # Mixed Precision\n",
    "\n",
    "                #     print(f\"Output dimensions: output.shape = {output.shape}\")\n",
    "\n",
    "                output, _ = run_snn(x_local)  # Assuming run_snn() is integrated into model\n",
    "                log_p_y = log_softmax_fn(output)  # LogSoftmax across all classes\n",
    "                loss_val = loss_fn(log_p_y, y_local)\n",
    "\n",
    "                # Backward pass\n",
    "                # if scaler:  # Mixed precision handling\n",
    "                #     scaler.scale(loss_val).backward()\n",
    "                #     scaler.step(optimizer)\n",
    "                #     scaler.update()\n",
    "                # else:\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                t.set_postfix(loss=loss_val.item())\n",
    "\n",
    "                local_loss.append(loss_val.item())\n",
    "        mean_loss = np.mean(local_loss)\n",
    "        print(\"Epoch %i: loss=%.5f\"%(e+1,mean_loss))\n",
    "        loss_hist.append(mean_loss)\n",
    "\n",
    "    return loss_hist\n",
    "\n",
    "\n",
    "def compute_classification_accuracy(data_loader):\n",
    "    \"\"\" Computes classification accuracy on supplied data in batches. \"\"\"\n",
    "    accs = []\n",
    "    for x_local, y_local in data_loader:\n",
    "        output,_ = run_snn(x_local)\n",
    "        m,_= torch.max(output,1) # max over time\n",
    "        _,am=torch.max(m,1)      # argmax over output units\n",
    "        tmp = np.mean((y_local==am).detach().cpu().numpy()) # compare to labels\n",
    "        accs.append(tmp)\n",
    "    return np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 52452,
     "status": "error",
     "timestamp": 1741063396566,
     "user": {
      "displayName": "Nalini Ramanathan",
      "userId": "15018175460010335567"
     },
     "user_tz": 300
    },
    "id": "1F1sUPDdUwca",
    "outputId": "06971a3b-889b-43ad-8c3a-e8c1d1f8b8c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 1/30:   0%|          | 0/235 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions: x_local.shape = torch.Size([256, 100, 1156]), y_local.shape = torch.Size([256, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 1/30:   0%|          | 0/235 [00:52<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'output' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-4dc8616c51e4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-7f7fdaaa38b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, lr, nb_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Mixed Precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output dimensions: output.shape = {output.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_snn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_local\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming run_snn() is integrated into model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'output' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "loss_hist = train(train_loader, lr=2e-4, nb_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgr01yk8Uwca"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.3,2),dpi=150)\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wnp_xQkmUwca"
   },
   "outputs": [],
   "source": [
    "print(\"Training accuracy: %.3f\"%(compute_classification_accuracy(train_loader)))\n",
    "print(\"Test accuracy: %.3f\"%(compute_classification_accuracy(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpdPDu3zUwcb"
   },
   "outputs": [],
   "source": [
    "def get_mini_batch(data_loader, shuffle=False):\n",
    "    for ret in data_loader:\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LEuTXUiUwcb"
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = get_mini_batch(test_loader)\n",
    "output, other_recordings = run_snn(x_batch)\n",
    "mem_rec, spk_rec = other_recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-DlHE6_Uwcb"
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=100)\n",
    "plot_voltage_traces(mem_rec, spk_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eq0vUeX8Uwcb"
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(dpi=100)\n",
    "plot_voltage_traces(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ki31od_GUwcb"
   },
   "outputs": [],
   "source": [
    "# Let's plot the hiddden layer spiking activity for some input stimuli\n",
    "\n",
    "nb_plt = 4\n",
    "gs = GridSpec(1,nb_plt)\n",
    "fig= plt.figure(figsize=(7,3),dpi=150)\n",
    "for i in range(nb_plt):\n",
    "    plt.subplot(gs[i])\n",
    "    plt.imshow(spk_rec[i].detach().cpu().numpy().T,cmap=plt.cm.gray_r, origin=\"lower\" )\n",
    "    if i==0:\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Units\")\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlvGIJ3fUwcb"
   },
   "source": [
    "In conclusion, we see that already this simple spiking network solves the classification problem with ~85% accuracy, and there is plenty of room left for tweaking. However, the hidden layer activities do not look very biological. Although the network displays population sparseness in that only a subset of neurons are active at any given time, the individual neurons' firing rates are pathologically high. This pathology is not too surprising since we have not incentivized low activity levels in any way. We will create such an incentive to address this issue by activity regularization in one of the next tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CveITSXUwcb"
   },
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZGmZF44qUwcc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEFZBr_xUwcc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO3SgdWFUwcc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "snn_hybrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
